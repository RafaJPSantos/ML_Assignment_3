{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adam, Adamax, Nadam\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MNIST or CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(num_classes=10, img_rows=28, img_cols=28, mnist_flag=True):\n",
    "    '''Loads MNIST or CIFAR-10 based on boolean flag.\n",
    "    # Arguments\n",
    "        mnist_flag: True for MNIST and False for CIFAR-10.\n",
    "    '''\n",
    "    if mnist_flag:\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    else:\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "        input_shape = x_train.shape[1:]\n",
    "\n",
    "    if mnist_flag:\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return[(x_train, y_train), (x_test, y_test), (input_shape)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cnn_topology(input_shape, num_classes=10):\n",
    "    '''Builds the CNN.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_models(mnist_flag=True):\n",
    "    '''Trains the CNN using each optimizer and saves them in a pickle,\n 
    "       by default with the MNIST dataset.\n,
    "    # Arguments\n",
    "        mnist_flag: True for MNIST and False for CIFAR-10.\n",
    "    '''\n",
    "    # load dataset\n",
    "    (x_train, y_train), (x_test, y_test), (input_shape) = load_data(mnist_flag=mnist_flag)\n",
    "    \n",
    "    # build CNN\n",
    "    model = cnn_topology(input_shape)\n",
    "    print(model.summary())\n",
    "\n",
    "    # training parameters\n",
    "    epochs=20\n",
    "    batch_size=128\n",
    "    loss_function = keras.losses.categorical_crossentropy\n",
    "\n",
    "    # optimizers \n",
    "    optimizers = [SGD(), SGD(momentum=0.9), SGD(momentum=0.9, nesterov=True),\n",
    "                  RMSprop(), Adagrad(), Adam(), Adamax(), Nadam()]\n",
    "\n",
    "    # save file name\n",
    "    if mnist_flag:\n",
    "        save_name = \"mnist_model{}\"\n",
    "    else:\n",
    "        save_name = \"cifar10_model{}\"\n",
    "        \n",
    "    i = 1\n",
    "    # trains a model for each optimizer\n",
    "    for opt in optimizers:\n",
    "        model.compile(loss=loss_function,\n",
    "                      optimizer=opt,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_test, y_test))\n",
    "\n",
    "        # saves model in a pickle\n",
    "        var_name = save_name.format(i)\n",
    "        with open(var_name, 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)\n",
    "\n",
    "        i +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_models()\n",
    "train_models(mnist_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example code for loading a model and plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "for i in range(1,9):\n",
    "    var_name = \"mnist_model{}\".format(i)\n",
    "    history = pickle.load( open( var_name, \"rb\" ) )\n",
    "    plt.plot(history['loss'])\n",
    "    \n",
    "\n",
    "plt.title('MNIST train performance')\n",
    "plt.ylabel('training cost')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['SGD', 'SGD w/ momentum', 'SGD w/ Nesterov momentum',\n",
    "            'RMSProp', 'AdaGrad', 'Adam', 'Adamax', 'Nadam'], loc='upper right', prop={'size': 10})\n",
    "\n",
    "\n",
    "plt.savefig('mnist_train.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras custom training callbacks -- useful for some experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TerminateOnBaseline(Callback):\n",
    "    '''Callback that terminates training when either acc or val_acc reaches a specified baseline.\n",
    "    '''\n",
    "    def __init__(self, monitor='acc', baseline=0.9, verbose=0):\n",
    "        super(TerminateOnBaseline, self).__init__()\n",
    "        self.stopped = False\n",
    "        self.monitor = monitor\n",
    "        self.baseline = baseline\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(self.monitor)\n",
    "        if acc is not None:\n",
    "            if acc >= self.baseline:\n",
    "                self.stopped = True\n",
    "                self.model.stop_training = True\n",
    "                if self.verbose:\n",
    "                    print('Epoch %d: Reached baseline, terminating training' % (epoch+1))\n",
    "         \n",
    "        \n",
    "class TimedStopping(Callback):\n",
    "    '''Stop training when enough time has passed.\n",
    "    # Arguments\n",
    "        seconds: maximum time before stopping.\n",
    "        verbose: verbosity mode.\n",
    "    '''\n",
    "    def __init__(self, seconds=None, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.stopped = False\n",
    "        self.start_time = 0\n",
    "        self.seconds = seconds\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if time.time() - self.start_time > self.seconds:\n",
    "            self.stopped=True\n",
    "            self.model.stop_training = True\n",
    "            if self.verbose:\n",
    "                print('Stopping after %s seconds.' % self.seconds)\n",
    "\n",
    "                \n",
    "class TimeHistory(Callback):\n",
    "    '''Callback that stores the training time in seconds.\n",
    "    '''\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "        \n",
    "        \n",
    "        \n",
    "#time_callback = TimeHistory()\n",
    "#terminated_on_baseline = TerminateOnBaseline(monitor='acc', baseline=0.97, verbose=1)\n",
    "#timed_stopping = TimedStopping(seconds=180, verbose=1)\n",
    "#callbacks = [time_callback, terminated_on_baseline, timed_stopping]\n",
    "\n",
    "\n",
    "#print(time_callback.times)\n",
    "#print(terminated_on_baseline.stopped)\n",
    "#print(timed_stopping.stopped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
